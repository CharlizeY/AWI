{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns # for visualisation\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import random\n",
    "random.seed(15)\n",
    "\n",
    "# Default plotting parameters\n",
    "font = {'size'   : 18}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "base_dir = \"/Users/Cherry0904/desktop/ArtWorldInsights/ML_modelling/\" \n",
    "Xy = pd.read_csv(base_dir + 'all_data.csv', squeeze = True)\n",
    "\n",
    "y = Xy[['logprice']]\n",
    "X_cts = Xy[['database', 'medium', 'dimensions', 'Followers Per Post (FPP)', 'Instagram performance', 'ArtfactsPresence', 'InsPresence', 'WebsitePresence']]\n",
    "X = Xy[['database', 'medium', 'dimensions', 'Followers Per Post (FPP)', 'Instagram performance', 'ArtfactsPresence', 'InsPresence', 'WebsitePresence']]\n",
    "# print(Xy.columns)\n",
    "\n",
    "# Create instance of one-hot-encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Perform one-hot encoding on the columns of categorical variables \n",
    "X_encoder_df1 = pd.DataFrame(encoder.fit_transform(X[['database']]).toarray())\n",
    "X_encoder_df2 = pd.DataFrame(encoder.fit_transform(X[['medium']]).toarray())\n",
    "# print(X_encoder_df1.columns)\n",
    "X_encoder_df1.columns = ['artprice', 'artsper', 'degreeart', 'riseart', 'singulart']\n",
    "X_encoder_df2.columns = ['drawing', 'painting', 'photo']\n",
    "# print(X_encoder_df2)\n",
    "\n",
    "# Merge one-hot encoded columns back with original DataFrame\n",
    "X_final = X.join(X_encoder_df1)\n",
    "X_final = X_final.join(X_encoder_df2)\n",
    "X_final = X_final.drop(['database', 'medium'], axis=1)\n",
    "# X_final.drop(['medium'], axis=1)\n",
    "# print(X_final)\n",
    "\n",
    "# Train-test split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_final, y, test_size = 0.20 , random_state=15)\n",
    "\n",
    "# Create version with them together\n",
    "Xy_tr = pd.concat([X_tr, y_tr], axis = 1)\n",
    "\n",
    "# Normalise according to training data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_sc = scaler.transform(X_tr)\n",
    "X_te_sc = scaler.transform(X_te)\n",
    "\n",
    "# Futher split to Train-validation sets - 0.8, 0.1, 0.2\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size = 0.10 , random_state=250)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
