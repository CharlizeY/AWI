{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns # for visualisation\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import random\n",
    "random.seed(15)\n",
    "\n",
    "# Default plotting parameters\n",
    "font = {'size'   : 18}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset\n",
    "base_dir = \"/Users/Cherry0904/desktop/ArtWorldInsights/ML_modelling/\" \n",
    "Xy = pd.read_csv(base_dir + 'all_data.csv', squeeze = True)\n",
    "\n",
    "y = Xy[['logprice']]\n",
    "X_cts = Xy[['database', 'medium', 'dimensions', 'Followers Per Post (FPP)', 'Instagram performance', 'ArtfactsPresence', 'InsPresence', 'WebsitePresence']]\n",
    "X = Xy[['database', 'medium', 'dimensions', 'Followers Per Post (FPP)', 'Instagram performance', 'ArtfactsPresence', 'InsPresence', 'WebsitePresence']]\n",
    "# print(Xy.columns)\n",
    "\n",
    "# Create instance of one-hot-encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Perform one-hot encoding on the columns of categorical variables \n",
    "X_encoder_df1 = pd.DataFrame(encoder.fit_transform(X[['database']]).toarray())\n",
    "X_encoder_df2 = pd.DataFrame(encoder.fit_transform(X[['medium']]).toarray())\n",
    "# print(X_encoder_df1.columns)\n",
    "X_encoder_df1.columns = ['artprice', 'artsper', 'degreeart', 'riseart', 'singulart']\n",
    "X_encoder_df2.columns = ['drawing', 'painting', 'photo']\n",
    "# print(X_encoder_df2)\n",
    "\n",
    "# Merge one-hot encoded columns back with original DataFrame\n",
    "X_final = X.join(X_encoder_df1)\n",
    "X_final = X_final.join(X_encoder_df2)\n",
    "X_final = X_final.drop(['database', 'medium'], axis=1)\n",
    "# X_final.drop(['medium'], axis=1)\n",
    "# print(X_final)\n",
    "\n",
    "# Train-test split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_final, y, test_size = 0.20 , random_state=15)\n",
    "\n",
    "# Create version with them together\n",
    "Xy_tr = pd.concat([X_tr, y_tr], axis = 1)\n",
    "\n",
    "# Normalise according to training data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_sc = scaler.transform(X_tr)\n",
    "X_te_sc = scaler.transform(X_te)\n",
    "\n",
    "# Futher split to Train-validation sets - 0.8, 0.1, 0.2\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size = 0.10 , random_state=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative_mean_squared_error: -0.640\n",
      "Config: {'C': 100, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Set up the support vector regressor\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf', gamma = 'scale')\n",
    "# regressor.fit(X_tr_sc, y_tr)\n",
    "\n",
    "# Grid Search    \n",
    "# Define grid on hyperparameters\n",
    "# C controls the regularisation on the error distances\n",
    "grid = {'C': [0.1, 1, 10, 100], 'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "# Gamma is the kernel parameter\n",
    "# Lower gamma means far-away points are considered for drawing the decision boundary\n",
    "# grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# Define search - maximise the defined regression metric\n",
    "search = GridSearchCV(regressor, grid, scoring='neg_mean_squared_error', cv=6, n_jobs=-1)\n",
    "\n",
    "# Perform the search\n",
    "results = search.fit(X_tr_sc, y_tr)\n",
    "\n",
    "# Summarize\n",
    "print('Negative_mean_squared_error: %.3f' % results.best_score_)      \n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-square: 0.4973816801266232\n",
      "Test RMSE: 0.7952960972056212\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on the held-out test set\n",
    "regressor = SVR(kernel = 'rbf', C = 100, gamma = 'scale')\n",
    "regressor.fit(X_tr_sc, y_tr)\n",
    "pred = regressor.predict(X_te_sc)\n",
    "rmse = np.sqrt(mean_squared_error(y_te, pred))\n",
    "\n",
    "print(\"Test R-square:\", regressor.score(X_te_sc, y_te))\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
